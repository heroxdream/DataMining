fit = lm(Y ~ X)
summary(fit)
plot(X, Y)
abline(-1, 0.5, col = 1)
abline(fit, col = 2)
legend(x = 1.2, y = -1.5, legend = c("original", "fit"), col = 1:2, lwd = 1)
set.seed(1)
X = rnorm(100)
eps = rnorm(100, mean = 0, sd = sqrt(0.5))
Y = -1 + 0.5 * X + eps
fit = lm(Y ~ X)
summary(fit)
plot(X, Y)
abline(-1, 0.5, col = 1)
abline(fit, col = 2)
legend(x = 1.2, y = -1.5, legend = c("original", "fit"), col = 1:2, lwd = 1)
confint(fit.e)
fit.e = lm(Y ~ X)
confint(fit.e)
plot(fit1)
fit1 = lm(mpg ~ cylinders + displacement + horsepower + weight + acceleration + year + origin)
summary(fit1)
par(mfrow = c(2, 2))
plot(fit1)
rm(list = ls())
ls
ls()
rm(list = ls())
ls()
library(MASS)
attach(Boston)
Boston
rm(list = ls())
library(MASS)
attach(Boston)
fit.1 = lm(crim ~ age)
summary(fit.1)
par(mfrow = c(2,2))
plot(fit.1)
plot(crim~age)
plot(crim,age)
abline(fit.1)
plot(crim~age)
abline(fit.1)
?par
?Boston
coef(fit.age)
fit.age = lm(crim ~ age)
coef(fit.age)
coef(fit.age[1])
coef(fit.age[2])
coef(fit.age[1,1])
coef(fit.age[1,2])
coef(fit.age)
dim(coef(fit.age))
class(coef(fit.age))
coef(fit.age)
coef(fit)
coef(fit.age)
coef(fit.age$age)
coef(fit.age)
x = coef(fit.age)
x
plot(x)
plot(x[1])
plot(x[2])
x[1]
x[2]
coef(fit.age[1])
coef(fit.age[2])
coef(fit.age)[2]
fit.all = lm(crim ~ ., data = Boston)
coef(fit.all)
coef(fit.all)[-1]
plot(allvari.coef, univari.coef)
univari.coef = c(coef(fit.zn)[2], coef(fit.indus)[2], coef(fit.chas)[2], coef(fit.nox)[2], coef(fit.rm)[2], coef(fit.age)[2], coef(fit.dis)[2], coef(fit.rad)[2], coef(fit.tax)[2], coef(fit.ptratio)[2], coef(fit.black)[2], coef(fit.lstat)[2], coef(fit.medv)[2])
allvari.coef = coef(fit.all)[-1]
plot(allvari.coef, univari.coef)
poly(zn,3)
head(zn)
head(zn, 1)
head(zn, 10)
?poly
poly(1:10, 2)
polym(1:4, c(1, 4:6), degree = 3)
polym(1:4, degree = 3)
polym(1:4, degree = 3, raw = T)
I(x)
x
I(x^2)
fit.dis = lm(crim ~ dis)
summary(fit.dis)
par(mfrow = c(2,2))
plot(fit.dis)
library(MASS)
attach(Boston)
Str(Boston)
Str(Boston)
str(Boston)
fit = lm(crim ~ .)
summary(fit)
par(mfrow = c(2, 2))
plot(fit)
fit = lm(crim ~ ., data = Boston)
summary(fit)
par(mfrow = c(2, 2))
plot(fit)
names(fit)
residuals(fit)
names(fit)
effects(fit)
names(fit)
model(fit)
df.residual(fit)
qr(fit)
close all()
close all()
close all
close
new.x = data.frame(X = seq(300, 1000))
new.y <- predict(fit, newdata = new.x, se.fit=T, type="response")
plot(X, Y)
lines(new.x$X, new.y$fit)
exp(1)
x1 = 40
x2 = 3.5
z = -6 + 0.05x1 + x2
z = -6 + 0.05 * x1 + x2
z
1 / (1 + exp(-z))
ln(e)
ln(exp)
log(2)
log(exp)
log(2.71)
log(1)
2.5 / 0.05
sample(1:100, rep=T)
?sample
sample(1:100, rep=T) == 4
sum(sample(1:100, rep=T) == 4)
store = rep(NA, 10000)
for (i in 10000){}
for (i in 10000){
store[i] = sum(sampel(1:100, 100, rep=T) == 4) > 0
}
for (i in 10000){
store[i] = sum(sample(1:100, 100, rep=T) == 4) > 0
}
mean(store)
store[i] = sum(sample(1:100, 100, rep=T) == 4) > 0
store
store = rep(NA, 10000)
for (i in 10000){
store[i] = sum(sample(1:100, 100, rep=T) == 4) > 0
}
store
for (i in 1:10000){
store[i] = sum(sample(1:100, 100, rep=T) == 4) > 0
}
store
mean(store)
v = c(0.17937428105037576, 0.23644057345065211, 0.2771963968989638, 0.3134103155615768, 0.3414553964952117, 0.3652366936608635, 0.3873103631452777, 0.40877637718593596, 0.42923961770682434, 0.4491048499623227, 0.4678427042022588, 0.48571317537474284, 0.5033080042690903, 0.5198369385535361, 0.5358369998279188, 0.5514388824648808, 0.5669333897745924, 0.5819568584131896, 0.5966051220446845, 0.6111213556023104, 0.6251293704337516, 0.6251293704337516, 0.6387395639869097, 0.6519376120332573, 0.6648484146292439, 0.6772333443859474, 0.6894258312906718, 0.7015352839053977, 0.7134287178242265, 0.7251753749227037, 0.7365378836520933, 0.7474298530713295, 0.7582134492880032, 0.7687923422270466, 0.7790673591991776, 0.7889799673237798, 0.7985106880950598, 0.8076644115438739)
dim(c)
dim(v)
length(v)
v = c(0.17937428105037576, 0.23644057345065211, 0.2771963968989638, 0.3134103155615768, 0.3414553964952117, 0.3652366936608635, 0.3873103631452777, 0.40877637718593596, 0.42923961770682434, 0.4491048499623227, 0.4678427042022588, 0.48571317537474284, 0.5033080042690903, 0.5198369385535361, 0.5358369998279188, 0.5514388824648808, 0.5669333897745924, 0.5819568584131896, 0.5966051220446845, 0.6111213556023104, 0.6251293704337516, 0.6251293704337516, 0.6387395639869097, 0.6519376120332573, 0.6648484146292439, 0.6772333443859474, 0.6894258312906718, 0.7015352839053977, 0.7134287178242265, 0.7251753749227037, 0.7365378836520933, 0.7474298530713295, 0.7582134492880032, 0.7687923422270466, 0.7790673591991776, 0.7889799673237798, 0.7985106880950598, 0.8076644115438739, 0.8164944854816076, 0.8250775540648161, 0.8331473144436904, 0.8428018819510614, 0.8428018819510614, 0.8496924528490588)
length(v)
v = c(0.18009492127634572, 0.23198194204464676, 0.27230457089749815, 0.30764992860287904, 0.3337252925790596, 0.358615956900391, 0.37955847700254813, 0.40320841273757113, 0.4234093516177111, 0.4447336456752792, 0.4625141761840992, 0.47978336898131174, 0.4971380066177357, 0.5133325415079674, 0.5289397485199369, 0.5444190773059163, 0.5597469593118125, 0.575062542128971, 0.5900263777116652, 0.6042937648165649, 0.6181720403733029, 0.6327206307885553, 0.6460563988966423, 0.659351308194748, 0.6726480151239808, 0.6848347310796561, 0.6973249431841627, 0.7098273298323354, 0.7219261109623716, 0.7334827118470232, 0.7454620398897119, 0.7563025546867728, 0.7676203727917413, 0.7781954920261911, 0.7885313896539596, 0.7986356995204801, 0.8086560984051452, 0.818439146528695, 0.8274755523584953, 0.8361245323539439, 0.8442880093685157, 0.8542243011433084, 0.8616073214942293, 0.8696652353546757, 0.8759987292342749, 0.8810799923780371, 0.8855301972891086, 0.8885044456619854, 0.8912310380831834)
length(v)
v = c(0.1801003965231573, 0.2369427990787749, 0.27677844263181933, 0.31273598273707054, 0.3403200565914482, 0.36362473464762324, 0.38612954989402226, 0.4075596477738489, 0.4278729716572815, 0.44745916538558694, 0.4662568481563327, 0.4841740611998995, 0.5015068593621833, 0.5177390757368266, 0.5334623970557353, 0.549059455382282, 0.5644153428579094, 0.5795879748540765, 0.594298453831497, 0.6087436797648305, 0.6227582316460978, 0.6365343534289247, 0.6502220247103051, 0.663460894354533, 0.6765004633071598, 0.6888871999186109, 0.701175641485526, 0.7132080536556308, 0.7251719758382993, 0.737006740913126, 0.7486176553564209, 0.7595952722305376, 0.7705205193126796, 0.7810589375478705, 0.7913562386717183, 0.8013351163187002, 0.8111511222461817, 0.8206377879013437, 0.829625204752851, 0.8381886255917161, 0.8460381944144497, 0.8559133886713459, 0.8628757179006334, 0.8697434080785894, 0.8763272674555098, 0.8825660573595511, 0.886974341674692, 0.8899336649496545, 0.8927983510494085, 0.8956187212362899, 0.8984134483030674, 0.9012145417944869)
length(v)
v = c(0.1819589599899191, 0.237388988604925, 0.27383236431206803, 0.307366056877003, 0.33922163631756774, 0.36652749340352525, 0.3889296293614383, 0.41026069152567346, 0.4311656587385021, 0.45075130728979684, 0.46920002809480493, 0.4872579973844178, 0.5046316441938202, 0.5212015488272502, 0.5373246082750298, 0.5531345486854065, 0.5684283247673668, 0.5836062702723998, 0.5982159472653347, 0.6127602211137093, 0.6267640282279098, 0.6406677384468388, 0.6543014534217204, 0.6676695993632853, 0.6807000536729514, 0.6932177516714766, 0.7054851816969349, 0.7174552029020135, 0.7292579141346491, 0.7407863305187223, 0.7522281502593081, 0.7631937749851395, 0.7739378844290178, 0.7843378505341556, 0.7942224285032813, 0.8037539666957334, 0.8131731821830709, 0.8220608299495544, 0.8305856106765467, 0.8384543050712826, 0.8481220669252909, 0.8555885731188777, 0.8622566493336933, 0.8688238230540457, 0.8752606906756459, 0.881530409280866, 0.8859220550725777, 0.8888493902736793, 0.8917508432750879, 0.8946026088283683, 0.8973836366008215, 0.900160837141633)
v = c(0.1764269205327787, 0.22803785357032094, 0.2613015338543853, 0.2940906859460997, 0.3041948772958358, 0.329842009665943, 0.3506180154273575, 0.37354501881848307, 0.39581401020325124, 0.42076074260634183, 0.43906236271213295, 0.4586767371135942, 0.4758830228953968, 0.49231454166589667, 0.5076748479901378, 0.5234098332234189, 0.5387270313222441, 0.55414166482, 0.5693926570521686, 0.5838340709762256, 0.5986696335666198, 0.6125850021308058, 0.626549246758372, 0.6398475912421414, 0.653291602708925, 0.6655484458337592, 0.6781205609729258, 0.6905724806852558, 0.7023324317021161, 0.7146135468822692, 0.726807313639287, 0.73802233387716, 0.7493869188016735, 0.7600258675137371, 0.7704710257923626, 0.7804099895283483, 0.7901750742082936, 0.7992586575717029, 0.808484500283834, 0.8169139638967748, 0.8264962450860014, 0.8340936509608757, 0.8497570777272697, 0.8542484834583974, 0.8566440997055162, 0.8614640195285634, 0.8658663911579046, 0.8688812459542888, 0.871755345004733, 0.8745031567864812, 0.8772756448214368, 0.8801087914009242, 0.8828477963351433, 0.8855345057733865, 0.887956000942263, 0.8900631669805321, 0.8922638325856804, 0.8943514925388156, 0.8952583872983039, 0.902140203273415)
v = c(0.1837962843312017, 0.2402688935800773, 0.2791040665033291, 0.31592360806689584, 0.3433632147453276, 0.36663304029194116, 0.38888615102688323, 0.4103197839711733, 0.4305063150515887, 0.4501059036559629, 0.4688523089500844, 0.4866358324985442, 0.5040063407969109, 0.520188047700665, 0.5360468208162781, 0.5514948769009553, 0.5667966276514186, 0.5817923875453863, 0.5964749914512516, 0.6109050999789597, 0.6249194567984766, 0.6385576577352056, 0.6519687666166588, 0.6652390813671745, 0.6781930949021217, 0.6905458644864829, 0.7026758930120744, 0.7146630570015046, 0.7263969379284835, 0.737999407832054, 0.7494966018036314, 0.7606385729990586, 0.7716138717331028, 0.7824560666965079, 0.7924886367744196, 0.8024476878228202, 0.812049046761367, 0.8213898682504113, 0.8304711315721267, 0.8389659366664343, 0.847284439549515, 0.8564333848934863, 0.8632942280609481, 0.8700556365555383, 0.8764579997359876, 0.8828034154561633, 0.8872117440310122, 0.8902017961970458, 0.8930888971783735, 0.8959053158685002, 0.8987052222203934, 0.9014830085439117)
c (18.088663895798, 23.6856622575123, 27.305432727709437, 30.630664228583484, 33.46973999454274, 36.194987336828504, 38.395846853858316, 40.55153336954256, 42.61774455346849, 44.55780141450692, 46.37737270564687, 48.22792279143846, 49.94939495764891, 51.61538461199327, 53.209312803281684, 54.768326507189734, 56.29218922227359, 57.82500494717933, 59.27594443977565, 60.73383640310135, 62.12430326908255, 63.47372619438901, 64.87476149887738, 66.21291161247444, 67.53820902379238, 68.76818238047915, 69.98761547000437, 71.23533375730321, 72.41736484784906, 73.59429169264287, 74.75917697183569, 75.86162813094572, 76.95142074934651, 78.00579006567177, 79.00470458627643, 80.01055532623819, 80.96853583824567, 81.91584907600725, 82.81297133266196, 83.66574623959434, 84.64229471792564, 85.42648158131122, 86.13593625140464, 86.81711407435317, 87.46328482665838, 88.10994786875969, 88.55039466982453, 88.84658033368737, 89.13350175243797, 89.41452351667984, 89.69110578804721, 89.96942451931876, 90.25171073792313)
v = c(18.088663895798, 23.6856622575123, 27.305432727709437, 30.630664228583484, 33.46973999454274, 36.194987336828504, 38.395846853858316, 40.55153336954256, 42.61774455346849, 44.55780141450692, 46.37737270564687, 48.22792279143846, 49.94939495764891, 51.61538461199327, 53.209312803281684, 54.768326507189734, 56.29218922227359, 57.82500494717933, 59.27594443977565, 60.73383640310135, 62.12430326908255, 63.47372619438901, 64.87476149887738, 66.21291161247444, 67.53820902379238, 68.76818238047915, 69.98761547000437, 71.23533375730321, 72.41736484784906, 73.59429169264287, 74.75917697183569, 75.86162813094572, 76.95142074934651, 78.00579006567177, 79.00470458627643, 80.01055532623819, 80.96853583824567, 81.91584907600725, 82.81297133266196, 83.66574623959434, 84.64229471792564, 85.42648158131122, 86.13593625140464, 86.81711407435317, 87.46328482665838, 88.10994786875969, 88.55039466982453, 88.84658033368737, 89.13350175243797, 89.41452351667984, 89.69110578804721, 89.96942451931876, 90.25171073792313)
1762244 / 1000
1.1784379262091083E7 / 1762244
1762244 / 1762
1762244 / 2000
2000*1000
878000/2000
877982 / 2000
2817907.3722950784 / 877982
2817907.3722950784 / 877982
2753824.116777961 / 877982
3013964 / 877982
2875729 / 877982
877982 / 2
v = c(18.088663895798, 23.6856622575123, 27.305432727709437, 30.630664228583484, 33.46973999454274, 36.194987336828504, 38.395846853858316, 40.55153336954256, 42.61774455346849, 44.55780141450692, 46.37737270564687, 48.22792279143846, 49.94939495764891, 51.61538461199327, 53.209312803281684, 54.768326507189734, 56.29218922227359, 57.82500494717933, 59.27594443977565, 60.73383640310135, 62.12430326908255, 63.47372619438901, 64.87476149887738, 66.21291161247444, 67.53820902379238, 68.76818238047915, 69.98761547000437, 71.23533375730321, 72.41736484784906, 73.59429169264287, 74.75917697183569, 75.86162813094572, 76.95142074934651, 78.00579006567177, 79.00470458627643, 80.01055532623819, 80.96853583824567, 81.91584907600725, 82.81297133266196, 83.66574623959434, 84.64229471792564, 85.42648158131122)
1497797 / 438991
881/2
9004946 / 438991
1500146.7553205255/ 438991
1426826.0597129762 / 438991
1426168 / 438991
1397083 / 438991
877982 / 100
9225381 / 438991
877982 / 200
1384039.9273547898 / 438991
1400700.567586148/ 438991
1385516.044791199 / 438991
137 * 0.2
v = c(0.1815638842230362, 0.23766928916676272, 0.2738074818016931, 0.30729722941117427, 0.3365458336848508, 0.3635622377369809, 0.3859288664824221, 0.4076757872382322, 0.4284128164652364, 0.4479043861226448, 0.4664837157152888, 0.48485792714664294, 0.5024511437247599, 0.519218706737143, 0.5353736437285144)
v = c(0.1815638842230362, 0.23766928916676272, 0.2738074818016931, 0.30729722941117427, 0.3365458336848508, 0.3635622377369809, 0.3859288664824221, 0.4076757872382322, 0.4284128164652364, 0.4479043861226448, 0.4664837157152888, 0.48485792714664294, 0.5024511437247599, 0.519218706737143, 0.5353736437285144, 0.5510159736843193, 0.5665264329571805, 0.5816169747535243, 0.5961453669610368, 0.6105219586604171, 0.6245185521995881, 0.6382347299359314, 0.6518035262415629, 0.6651676149737651, 0.6783725977046744)
1469448/ 438991
log(2, 23000)
log(23000)
binQua
load('realEstate.RData')
binQua = ifelse(realEstate$Quality == 1, 1, 0)
binQua = as.factor(binQua)
all.data = data.frame(realEstate, binQua)
setwd("~/Dropbox/neu/tools/github/data_mining/tree")
load('realEstate.RData')
binQua = ifelse(realEstate$Quality == 1, 1, 0)
binQua = as.factor(binQua)
all.data = data.frame(realEstate, binQua)
totalInstance = dim(realEstate)[1]
trainSize = 350
testSize = totalInstance - trainSize
set.seed(1)
trainIndex = sample(1:522, 350)
trainSet = all.data[trainIndex, c(-1, -10)]
validateSet = all.data[-trainIndex, c(-1, -10)]
require(gbm)
set.seed(1)
shirinkages = seq(from = 0, to = 0.4, by = 0.01)
trainAccu = rep(NA, length(shirinkages))
testAccu = rep(NA, length(shirinkages))
counter = 1
trainSet$binQua = as.numeric(trainSet$binQua)
str(trainSet)
validateSet$binQua = as.numeric(validateSet$binQua)
boost.realEstate = gbm(binQua ~ ., data = trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = 0.001)
binQua
str(trainSet)
boost.realEstate = gbm(binQua ~ . - binQua, data = trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = 0.001)
boost.realEstate = gbm(trainSet$binQua ~ ., data = trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = 0.001)
boost.realEstate = gbm(trainSet$binQua, trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = 0.001)
boost.realEstate = gbm(binQua~., data = trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = 0.001)
trainSet$binQua
validateSet$binQua
load('realEstate.RData')
binQua = ifelse(realEstate$Quality == 1, 1, 0)
binQua = as.factor(binQua)
all.data = data.frame(realEstate, binQua)
totalInstance = dim(realEstate)[1]
trainSize = 350
testSize = totalInstance - trainSize
set.seed(1)
trainIndex = sample(1:522, 350)
trainSet = all.data[trainIndex, c(-1, -10)]
validateSet = all.data[-trainIndex, c(-1, -10)]
binQua
binQua
all.data
class(binQua)
trainSet
str(trainSet)
summary(trainSet)
trainSet$binQua
trainSet$binQua = as.numeric(trainSet$binQua) - 1
validateSet$binQua = as.numeric(validateSet$binQua) -1
boost.realEstate = gbm(binQua ~ ., data = trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = 0.001)
boost.realEstate
boost.realEstate$train.error
boost.realEstate$response.name
boost.realEstate$nTrain
boost.realEstate$verbose
yhat.boost.array = predict(boost.realEstate, newdata = validateSet, n.trees = 1000, type = 'response')
yhat.boost.array
yhat.boost.vali.array = predict(boost.realEstate, newdata = validateSet, n.trees = 1000, type = 'response')
yhat.boost.vali.probs = predict(boost.realEstate, newdata = validateSet, n.trees = 1000, type = 'response')
yhat.boost.vali.preds = ifelse(yhat.boost.vali.probs > 0.5, 1, 0)
yhat.boost.vali.preds
?ifelse
yhat.boost.train.probs = predict(boost.realEstate, newdata = trainSet, n.trees = 1000, type = 'response')
yhat.boost.train.preds = ifelse(yhat.boost.train.probs > 0.5, 1, 0)
yhat.boost.train.preds
sum(yhat.boost.vali.preds == validateSet$binQua) / 172
1 - sum(yhat.boost.vali.preds == validateSet$binQua) / 172
1 - sum(yhat.boost.train.preds == trainSet$binQua) / 350
for (s in shirinkages) {
boost.realEstate = gbm(binQua ~ ., data = trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = s)
yhat.boost.vali.probs = predict(boost.realEstate, newdata = validateSet, n.trees = 1000, type = 'response')
yhat.boost.vali.preds = ifelse(yhat.boost.vali.probs > 0.5, 1, 0)
yhat.boost.train.probs = predict(boost.realEstate, newdata = trainSet, n.trees = 1000, type = 'response')
yhat.boost.train.preds = ifelse(yhat.boost.train.probs > 0.5, 1, 0)
trainAccu[counter] = 1 - sum(yhat.boost.train.preds == trainSet$binQua) / 350
testAccu[counter] = 1 - sum(yhat.boost.vali.preds == validateSet$binQua) / 172
counter = counter + 1
}
par(mfrow = c(2, 2))
plot(shirinkages, trainAccu, type = 'l')
plot(shirinkages, testAccu, type = 'l')
best = which.max(testAccu)
testAccu[best]
trainAccu[best]
summary(boost.realEstate)
require(gbm)
set.seed(1)
shirinkages = seq(from = 0, to = 0.4, by = 0.01)
trainAccu = rep(NA, length(shirinkages))
testAccu = rep(NA, length(shirinkages))
counter = 1
trainSet$binQua = as.numeric(trainSet$binQua) - 1
validateSet$binQua = as.numeric(validateSet$binQua) - 1
boost.realEstate = gbm(binQua ~ ., data = trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = s)
yhat.boost.vali.probs = predict(boost.realEstate, newdata = validateSet, n.trees = 1000, type = 'response')
yhat.boost.vali.preds = ifelse(yhat.boost.vali.probs > 0.5, 1, 0)
yhat.boost.train.probs = predict(boost.realEstate, newdata = trainSet, n.trees = 1000, type = 'response')
yhat.boost.train.preds = ifelse(yhat.boost.train.probs > 0.5, 1, 0)
trainAccu[counter] = 1 - sum(yhat.boost.train.preds == trainSet$binQua) / 350
testAccu[counter] = 1 - sum(yhat.boost.vali.preds == validateSet$binQua) / 172
counter = counter + 1
}
par(mfrow = c(2, 2))
plot(shirinkages, trainAccu, type = 'l')
plot(shirinkages, testAccu, type = 'l')
best = which.max(testAccu)
testAccu[best]
trainAccu[best]
summary(boost.realEstate)
for (s in shirinkages) {
boost.realEstate = gbm(binQua ~ ., data = trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = s)
yhat.boost.vali.probs = predict(boost.realEstate, newdata = validateSet, n.trees = 1000, type = 'response')
yhat.boost.vali.preds = ifelse(yhat.boost.vali.probs > 0.5, 1, 0)
yhat.boost.train.probs = predict(boost.realEstate, newdata = trainSet, n.trees = 1000, type = 'response')
yhat.boost.train.preds = ifelse(yhat.boost.train.probs > 0.5, 1, 0)
trainAccu[counter] = 1 - sum(yhat.boost.train.preds == trainSet$binQua) / 350
testAccu[counter] = 1 - sum(yhat.boost.vali.preds == validateSet$binQua) / 172
counter = counter + 1
}
par(mfrow = c(2, 2))
plot(shirinkages, trainAccu, type = 'l')
plot(shirinkages, testAccu, type = 'l')
best = which.max(testAccu)
1 - testAccu[best]
1 - trainAccu[best]
summary(boost.realEstate)
require(gbm)
shirinkages = seq(from = 0, to = 1, by = 0.01)
trainAccu = rep(NA, length(shirinkages))
testAccu = rep(NA, length(shirinkages))
counter = 1
trainSet$binQua = as.numeric(trainSet$binQua) - 1
validateSet$binQua = as.numeric(validateSet$binQua) - 1
for (s in shirinkages) {
boost.realEstate = gbm(binQua ~ ., data = trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = s)
yhat.boost.vali.probs = predict(boost.realEstate, newdata = validateSet, n.trees = 1000, type = 'response')
yhat.boost.vali.preds = ifelse(yhat.boost.vali.probs > 0.5, 1, 0)
yhat.boost.train.probs = predict(boost.realEstate, newdata = trainSet, n.trees = 1000, type = 'response')
yhat.boost.train.preds = ifelse(yhat.boost.train.probs > 0.5, 1, 0)
trainAccu[counter] = 1 - sum(yhat.boost.train.preds == trainSet$binQua) / 350
testAccu[counter] = 1 - sum(yhat.boost.vali.preds == validateSet$binQua) / 172
counter = counter + 1
}
par(mfrow = c(2, 2))
plot(shirinkages, trainAccu, type = 'l')
plot(shirinkages, testAccu, type = 'l')
best = which.max(testAccu)
1 - testAccu[best]
1 - trainAccu[best]
summary(boost.realEstate)
require(gbm)
shirinkages = seq(from = 0, to = 0.5, by = 0.01)
trainAccu = rep(NA, length(shirinkages))
testAccu = rep(NA, length(shirinkages))
counter = 1
trainSet$binQua = as.numeric(trainSet$binQua) - 1
validateSet$binQua = as.numeric(validateSet$binQua) - 1
for (s in shirinkages) {
boost.realEstate = gbm(binQua ~ ., data = trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = s)
yhat.boost.vali.probs = predict(boost.realEstate, newdata = validateSet, n.trees = 1000, type = 'response')
yhat.boost.vali.preds = ifelse(yhat.boost.vali.probs > 0.5, 1, 0)
yhat.boost.train.probs = predict(boost.realEstate, newdata = trainSet, n.trees = 1000, type = 'response')
yhat.boost.train.preds = ifelse(yhat.boost.train.probs > 0.5, 1, 0)
trainAccu[counter] = 1 - sum(yhat.boost.train.preds == trainSet$binQua) / 350
testAccu[counter] = 1 - sum(yhat.boost.vali.preds == validateSet$binQua) / 172
counter = counter + 1
}
par(mfrow = c(2, 2))
plot(shirinkages, trainAccu, type = 'l')
plot(shirinkages, testAccu, type = 'l')
best = which.max(testAccu)
1 - testAccu[best]
1 - trainAccu[best]
summary(boost.realEstate)
require(gbm)
shirinkages = seq(from = 0, to = 0.8, by = 0.01)
trainAccu = rep(NA, length(shirinkages))
testAccu = rep(NA, length(shirinkages))
counter = 1
trainSet$binQua = as.numeric(trainSet$binQua) - 1
validateSet$binQua = as.numeric(validateSet$binQua) - 1
for (s in shirinkages) {
boost.realEstate = gbm(binQua ~ ., data = trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = s)
yhat.boost.vali.probs = predict(boost.realEstate, newdata = validateSet, n.trees = 1000, type = 'response')
yhat.boost.vali.preds = ifelse(yhat.boost.vali.probs > 0.5, 1, 0)
yhat.boost.train.probs = predict(boost.realEstate, newdata = trainSet, n.trees = 1000, type = 'response')
yhat.boost.train.preds = ifelse(yhat.boost.train.probs > 0.5, 1, 0)
trainAccu[counter] = 1 - sum(yhat.boost.train.preds == trainSet$binQua) / 350
testAccu[counter] = 1 - sum(yhat.boost.vali.preds == validateSet$binQua) / 172
counter = counter + 1
}
par(mfrow = c(2, 2))
plot(shirinkages, trainAccu, type = 'l')
plot(shirinkages, testAccu, type = 'l')
best = which.max(testAccu)
1 - testAccu[best]
1 - trainAccu[best]
summary(boost.realEstate)
require(gbm)
set.seed(1)
shirinkages = seq(from = 0, to = 0.5, by = 0.01)
trainAccu = rep(NA, length(shirinkages))
testAccu = rep(NA, length(shirinkages))
counter = 1
trainSet$binQua = as.numeric(trainSet$binQua) - 1
validateSet$binQua = as.numeric(validateSet$binQua) - 1
for (s in shirinkages) {
boost.realEstate = gbm(binQua ~ ., data = trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = s)
yhat.boost.vali.probs = predict(boost.realEstate, newdata = validateSet, n.trees = 1000, type = 'response')
yhat.boost.vali.preds = ifelse(yhat.boost.vali.probs > 0.5, 1, 0)
yhat.boost.train.probs = predict(boost.realEstate, newdata = trainSet, n.trees = 1000, type = 'response')
yhat.boost.train.preds = ifelse(yhat.boost.train.probs > 0.5, 1, 0)
trainAccu[counter] = 1 - sum(yhat.boost.train.preds == trainSet$binQua) / 350
testAccu[counter] = 1 - sum(yhat.boost.vali.preds == validateSet$binQua) / 172
counter = counter + 1
}
par(mfrow = c(2, 2))
plot(shirinkages, trainAccu, type = 'l')
plot(shirinkages, testAccu, type = 'l')
best = which.max(testAccu)
1 - testAccu[best]
1 - trainAccu[best]
summary(boost.realEstate)
require(gbm)
set.seed(1)
shirinkages = seq(from = 0, to = 0.6, by = 0.02)
trainAccu = rep(NA, length(shirinkages))
testAccu = rep(NA, length(shirinkages))
counter = 1
trainSet$binQua = as.numeric(trainSet$binQua) - 1
validateSet$binQua = as.numeric(validateSet$binQua) - 1
for (s in shirinkages) {
boost.realEstate = gbm(binQua ~ ., data = trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = s)
yhat.boost.vali.probs = predict(boost.realEstate, newdata = validateSet, n.trees = 1000, type = 'response')
yhat.boost.vali.preds = ifelse(yhat.boost.vali.probs > 0.5, 1, 0)
yhat.boost.train.probs = predict(boost.realEstate, newdata = trainSet, n.trees = 1000, type = 'response')
yhat.boost.train.preds = ifelse(yhat.boost.train.probs > 0.5, 1, 0)
trainAccu[counter] = sum(yhat.boost.train.preds == trainSet$binQua) / 350
testAccu[counter] = sum(yhat.boost.vali.preds == validateSet$binQua) / 172
counter = counter + 1
}
par(mfrow = c(2, 2))
plot(shirinkages, trainAccu, type = 'l')
plot(shirinkages, testAccu, type = 'l')
best = which.max(testAccu)
1 - testAccu[best]
1 - trainAccu[best]
summary(boost.realEstate)
load('realEstate.RData')
binQua = ifelse(realEstate$Quality == 1, 1, 0)
binQua = as.factor(binQua)
all.data = data.frame(realEstate, binQua)
totalInstance = dim(realEstate)[1]
trainSize = 350
testSize = totalInstance - trainSize
set.seed(1)
trainIndex = sample(1:522, 350)
trainSet = all.data[trainIndex, c(-1, -10)]
validateSet = all.data[-trainIndex, c(-1, -10)]
load('realEstate.RData')
binQua = ifelse(realEstate$Quality == 1, 1, 0)
binQua = as.factor(binQua)
all.data = data.frame(realEstate, binQua)
totalInstance = dim(realEstate)[1]
trainSize = 350
testSize = totalInstance - trainSize
set.seed(1)
trainIndex = sample(1:522, 350)
trainSet = all.data[trainIndex, c(-1, -10)]
validateSet = all.data[-trainIndex, c(-1, -10)]
require(gbm)
set.seed(1)
shirinkages = seq(from = 0, to = 0.6, by = 0.02)
trainAccu = rep(NA, length(shirinkages))
testAccu = rep(NA, length(shirinkages))
counter = 1
trainSet$binQua = as.numeric(trainSet$binQua) - 1
validateSet$binQua = as.numeric(validateSet$binQua) - 1
for (s in shirinkages) {
boost.realEstate = gbm(binQua ~ ., data = trainSet, distribution = "bernoulli", n.trees = 1000, shrinkage = s)
yhat.boost.vali.probs = predict(boost.realEstate, newdata = validateSet, n.trees = 1000, type = 'response')
yhat.boost.vali.preds = ifelse(yhat.boost.vali.probs > 0.5, 1, 0)
yhat.boost.train.probs = predict(boost.realEstate, newdata = trainSet, n.trees = 1000, type = 'response')
yhat.boost.train.preds = ifelse(yhat.boost.train.probs > 0.5, 1, 0)
trainAccu[counter] = sum(yhat.boost.train.preds == trainSet$binQua) / 350
testAccu[counter] = sum(yhat.boost.vali.preds == validateSet$binQua) / 172
counter = counter + 1
}
par(mfrow = c(2, 2))
plot(shirinkages, trainAccu, type = 'l')
plot(shirinkages, testAccu, type = 'l')
best = which.max(testAccu)
1 - testAccu[best]
1 - trainAccu[best]
summary(boost.realEstate)
